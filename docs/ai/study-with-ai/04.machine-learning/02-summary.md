# 02. Summary

## 왜 모델은 “잘” 혹은 “너무 잘” 배울까?

## 1️⃣ 출발점: 학습이 잘 됐다는 건 무엇인가?

- **학습 데이터에 잘 맞히는 것**은 기본 전제
- 그것만으로는 “똑똑하다”고 할 수 없다
- **학습되지 않은 데이터에서도 정답에 가까워야** 똑똑하다고 판단할 수 있다

👉 여기서 평가 기준이 이동한다
**훈련 성능 → 일반화 성능**

## 2️⃣ 일반화(Generalization)

- 모델이 **본 적 없는 데이터**에서도
- 학습에서 얻은 패턴을 활용해
- 합리적인 결과를 내는 능력

👉 지능을 판단하는 핵심 기준

## 3️⃣ 과소적합과 과적합

### 과소적합 (Underfitting)

- 학습 데이터에도 성능이 낮다
- 모델이 너무 단순하거나
- 데이터의 구조를 충분히 못 배움
- **Bias가 큼**

### 과적합 (Overfitting)

- 학습 데이터에는 매우 강하다
- 새로운 데이터에는 약하다
- 세부 패턴·노이즈까지 외워버림
- **Variance가 큼**

👉 “너무 잘 배우는 것”도 실패의 한 형태

## 4️⃣ Bias – Variance 관점

- **Bias**: 항상 비슷하게 틀리는 경향
  → 모델이 단순, 표현력 부족

- **Variance**: 결과가 들쭉날쭉
  → 데이터에 과도하게 민감

중요한 점:

- Bias와 Variance는 **동시에 줄일 수 없다**
- 학습은 이 둘의 **균형을 잡는 문제**

## 5️⃣ 판단은 어떻게 하는가?

모델 내부를 들여다보지 않는다.
**결과만 비교한다.**

- Train 성능
- Validation / Test 성능

이 조합으로 상태를 판단한다.

| Train | Test | 상태          |
| ----- | ---- | ------------- |
| 낮음  | 낮음 | 과소적합      |
| 높음  | 낮음 | 과적합        |
| 높음  | 높음 | 이상적인 상태 |

## 6️⃣ 중요한 관점 전환

- 과적합 / 과소적합은
  - 모델의 고정된 속성이 아니다

- 데이터, 문제 정의, 학습 방식에 따라
  - **상태가 바뀐다**

👉 “과적합 모델”이 아니라
👉 **“과적합 상태”**

## 7️⃣ Week 4 핵심 문장 (이거 하나만 기억해도 됨)

> **학습이 잘 됐는지는
> 학습 데이터가 아니라
> 학습되지 않은 데이터가 말해준다**

여기까지면 **Week 4 목표는 완전히 달성**했습니다.
다음으로 자연스럽게 이어지는 건 딱 하나입니다.

- **Week 5: 과적합을 줄이는 방법들**
  - 규제(regularization)
  - 데이터 분할
  - 모델 복잡도 조절
