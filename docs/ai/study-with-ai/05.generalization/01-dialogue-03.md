# 01. Dialogue Log - 03

## 1️⃣ Elastic Net — L1 + L2는 왜 섞였나?

![Image](https://cdn.corporatefinanceinstitute.com/assets/elastic-net1.png)

![Image](https://miro.medium.com/0%2A-aJ9MXozOKv6joiX.png)

![Image](https://media.licdn.com/dms/image/v2/C5612AQEJQE6b_4Q7TQ/article-cover_image-shrink_600_2000/article-cover_image-shrink_600_2000/0/1527370562133?e=2147483647&t=jlH0HuahY7TlmQC8IVTucm_32_seGwpjrVYNaQjIyg4&v=beta)

### 다시 출발점부터

- **L1 (Lasso)**
  - 가중치를 **0으로 만들어서** feature selection 효과
  - 하지만 feature들이 **강하게 상관**되어 있으면 불안정
    → 하나만 남기고 나머지를 버려버림

- **L2 (Ridge)**
  - 가중치를 **작게 분산**시켜 안정성 ↑
  - 하지만 **0은 거의 안 됨**
    → feature가 많아질수록 해석이 어려움

여기서 나온 질문:

> “**선택 능력(L1)** + **안정성(L2)** 을 동시에 가질 수 없을까?”

👉 그 답이 **Elastic Net**

### Elastic Net의 핵심 아이디어

손실 함수에 들어가는 패널티가 이렇게 생김:

```
[\lambda \big( \alpha |w|_1 + (1-\alpha)|w|_2^2 \big)]
```

- (\alpha = 1) → L1
- (\alpha = 0) → L2
- **그 사이 어딘가** → Elastic Net

### 직관적으로 말하면

- L1이 **“쓸모없는 애는 꺼져”** 라면
- L2는 **“다 같이 조금씩만 하자”**

Elastic Net은:

> “팀 단위로 의미 있는 애들은 남기되,
> 각자 너무 튀지는 말자”

### 언제 Elastic Net이 특히 좋을까?

- feature 수가 많다
- feature들끼리 **상관관계가 강하다**
- 완전한 sparse 모델은 싫고
- 그렇다고 ridge처럼 다 들고 가기도 싫다

👉 **현실 데이터에서 매우 흔한 상황**

그래서 실제 실무에서는

> “Lasso or Ridge” 보다
> **Elastic Net이 기본 옵션**인 경우가 많다.

## 2️⃣ 정규화의 한계 — 이거 중요한 포인트야

여기서 반드시 한 번 멈춰야 한다.

### ❗ 정규화가 해결하지 못하는 것들

#### 1. 데이터 자체가 이상할 때

- 라벨 노이즈가 심함
- 측정 오류
- 데이터 수가 너무 적음

👉 정규화는 **데이터를 깨끗하게 만들지 못한다**

#### 2. 모델 가정이 틀렸을 때

- 선형 모델로 비선형 문제를 풀려고 함
- 중요한 feature 자체가 빠져 있음

👉 정규화는 **틀린 가설을 고쳐주지 않는다**

#### 3. Bias 문제

- underfitting 상황
- 이미 너무 단순한 모델

👉 정규화는 **Bias를 줄이는 도구가 아니다**
(오히려 Bias를 늘리는 쪽)

### 이 문장 하나만 기억해도 된다

> **정규화는 “과한 자유도”를 제어할 뿐,
> 잘못된 문제 설정을 구해주지는 않는다**

## 3️⃣ 데이터 / 모델 / 정규화 선택 기준 (실전 사고 프레임)

이제 “뭘 쓰냐”보다
**“어떤 순서로 생각하냐”**가 중요해진다.

### ① 항상 1순위: 데이터

먼저 물어야 할 질문들:

- 데이터 수는 충분한가?
- 노이즈가 많은가?
- feature 간 상관관계는?

👉 이걸 안 보고 정규화부터 만지는 건
**렌즈 더러운 카메라에 필터만 바꾸는 격**

### ② 그 다음: 모델 복잡도

- 데이터 적음 + feature 적음
  → 단순 모델

- 데이터 많음 + 패턴 복잡
  → 복잡한 모델 고려

👉 모델 자유도는 **데이터가 허락하는 만큼만**

### ③ 마지막에: 정규화

정규화는 항상 **미세 조정 단계**다.

| 상황                   | 선택        |
| ---------------------- | ----------- |
| feature selection 필요 | L1          |
| 안정성, 일반화 중시    | L2          |
| 둘 다 필요             | Elastic Net |

👉 정규화는 **주연이 아니라 조연**

## 4️⃣ Week 5 최종 Summary (summary.md용)

> **Week 5의 핵심 관점**

- 일반화 문제는 **모델만의 문제가 아니다**
- 자유도는 높을수록 위험하다
- 정규화는 가중치를 제어해 variance를 낮춘다
- L1은 선택, L2는 안정, Elastic Net은 절충
- 정규화는 데이터/모델 선택을 대신해주지 않는다
