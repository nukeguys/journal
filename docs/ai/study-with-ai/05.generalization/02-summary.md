# 02. Summary

## 1. Week 5의 핵심 질문

- **일반화는 왜 자동으로 생기지 않는가?**
- **사람은 어디에 개입해서 일반화를 유도하는가?**

## 2. 일반화(Generalization)의 정확한 의미

- 일반화란 **학습 데이터에서의 성능이 보지 않은 데이터에서도 유지되는 성질**
- 관측 관점에서는:
  - 평균 성능이 크게 떨어지지 않고
  - 결과의 흔들림(분산)이 크지 않음

- 따라서:
  - **분산을 낮추는 것은 일반화를 달성하기 위한 핵심 수단 중 하나**
  - 하지만 일반화 = 분산 감소는 아님
  - 핵심은 **보지 않은 데이터에서도 성능이 유지되는가**

## 3. 자유도 관점에서 본 과적합

- 모델은 손실만 줄이면 되기 때문에
  - 노이즈
  - 우연한 패턴
  - 특정 feature에 대한 과도한 의존
    을 선택할 수 있음

- 이것이 **과적합**
- 해결책:
  - **모델이 선택할 수 있는 해의 공간을 줄인다**
  - 즉, **자유도를 제어한다**

## 4. 모델 자유도를 결정하는 요소들

모델의 자유도는 하나로 정해지지 않는다.

1. **모델 구조**
   - 파라미터 수
   - 깊이
   - 표현력

2. **데이터**
   - 데이터 양
   - 데이터 다양성
   - 입력 범위  
     → 데이터는 구조가 아니지만 **유효 자유도**를 제한함

3. **학습 과정**
   - 손실 함수
   - 규제(정규화)
   - 학습 전략

## 5. 정규화(Regularization)의 철학

- 정규화는:
  - 성능 평가 단계에서 분산을 “보는 것”이 아니라
  - 학습 중에 **그런 모델이 선택되지 않도록 미리 제약**

- 목적:
  - 극단적인 해 선택 방지
  - 모델의 과도한 확신 억제
  - Variance 감소 → 일반화 개선

## 6. 가중치와 Variance의 관계

- 가중치 = 특정 입력에 대한 **확신의 정도**
- 가중치가 너무 크면:
  - 입력의 작은 변화 → 출력의 큰 변화
  - 모델 민감도 증가
  - **Variance 증가**

- 이것은 Bias 문제가 아니라 **Variance 문제**

## 7. L1 / L2 정규화 (개념)

- L1 / L2는 **레이어가 아님**
- 손실 함수에 추가되는 **벌점의 형태 차이**

### L2 정규화 (Ridge)

- 가중치를 제곱해서 벌
- 모든 가중치를 작게 유지
- 여러 feature를 골고루 사용
- 결과:
  - 안정적
  - 부드러운 결정 경계
  - **범용적인 모델**

- 실무 기본값

### L1 정규화 (Lasso)

- 가중치 절댓값에 비례해 벌
- 많은 가중치를 0으로 만듦
- 일부 feature만 선택
- 결과:
  - 희소한 모델
  - 특정 패턴에 강함
  - 해석 용이

- **특화된 모델**

## 8. Elastic Net — 선택과 안정성의 절충

- Elastic Net은 **L1과 L2를 동시에 사용**
- 목적:
  - L1의 feature 선택 능력
  - L2의 안정성과 일반화 성질
    를 함께 얻기 위함

- 특히:
  - feature 수가 많고
  - feature 간 상관관계가 강한 데이터에서
    L1 단독의 불안정을 완화

- 현실 데이터에서는:
  - 순수 L1 / L2보다
  - **Elastic Net이 기본 선택이 되는 경우가 많음**

## 9. 정규화의 한계

정규화는 만능이 아니다.

정규화로 해결할 수 **없는** 문제들:

- 데이터 자체의 문제
  - 라벨 노이즈
  - 데이터 부족
  - 측정 오류

- 모델 가정의 문제
  - 선형 모델로 비선형 문제를 푸는 경우
  - 중요한 feature가 누락된 경우

- Bias 문제
  - 이미 너무 단순한 모델의 underfitting

> **정규화는
> 잘못된 문제 설정을 고쳐주지 않는다.**

## 10. 데이터 / 모델 / 정규화 선택의 우선순위

일반화 문제를 볼 때의 사고 순서:

1. **데이터**
   - 충분한가?
   - 신뢰할 수 있는가?

2. **모델**
   - 데이터가 허용하는 복잡도인가?

3. **정규화**
   - 과도한 자유도를 제어하는 미세 조정 단계

정규화는 항상 **마지막 단계의 선택지**다.

## 11. Week 5를 관통하는 핵심 문장

> **정규화는  
> 모델에게 “확신을 너무 크게 갖지 말라”는  
> 취향을 강요하는 장치다.**

그리고 더 중요한 관점:

> **일반화는  
> 단일 기법의 결과가 아니라  
> 데이터, 모델, 제약 선택의 종합 결과다.**
